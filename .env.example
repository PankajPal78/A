# LLM Provider Configuration
# Choose one: "gemini", "openai", or "ollama"
LLM_PROVIDER=gemini

# API Keys (required based on provider)
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (if using Ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Application Configuration
FLASK_ENV=development
FLASK_DEBUG=True
UPLOAD_FOLDER=./data/uploads
VECTOR_DB_PATH=./data/vectordb
DATABASE_URL=sqlite:///./data/documents.db

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Retrieval Configuration
TOP_K_RESULTS=5